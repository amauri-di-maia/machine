name: Brickovery - M2 Refresh Market Cache

on:
  workflow_dispatch:
    inputs:
      note:
        description: "Optional note (no effect)."
        required: false
        default: ""

concurrency:
  group: brickovery-m2-main
  cancel-in-progress: false

permissions:
  contents: write

jobs:
  m2:
    runs-on: ubuntu-latest
    env:
      # RUN_ID used by Brickovery logs/outputs; keep UTC, deterministic format
      RUN_ID: ${{ github.run_id }}

    steps:
      - name: Checkout machine repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Clone upstream repo (read-only)
        env:
          UP_TOKEN: ${{ secrets.UPSTREAM_REPO_TOKEN }}
          UPSTREAM_REPO: amauri-di-maia/amauri-repo
          UPSTREAM_REF: main
        run: |
          set -euo pipefail
          rm -rf "upstream/amauri-repo" || true
          mkdir -p upstream
          git clone --depth 1 --branch "${UPSTREAM_REF}" "https://x-access-token:${UP_TOKEN}@github.com/${UPSTREAM_REPO}.git" "upstream/amauri-repo"
          echo "UPSTREAM_COMMIT_SHA=$(git -C upstream/amauri-repo rev-parse HEAD)" >> "$GITHUB_ENV"

      - name: Verify upstream brickovery.db is SQLite
        run: |
          set -euo pipefail
          DB="upstream/amauri-repo/data base/brickovery.db"
          ls -la "$DB"
          python - <<'PY'
          p="upstream/amauri-repo/data base/brickovery.db"
          with open(p,"rb") as f:
              head=f.read(16)
          if head.startswith(b"version https://git-lfs.github.com/spec/v1"):
              raise SystemExit("Upstream DB is a Git LFS pointer (not SQLite). Re-upload brickovery.db without LFS.")
          if not head.startswith(b"SQLite format 3\0"):
              raise SystemExit(f"Upstream DB is not SQLite. Header={head!r}")
          print("OK: upstream DB is SQLite.")
          PY

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          fi
          sudo apt-get update
          sudo apt-get install -y sqlite3

      - name: Run M2 refresh-cache
        env:
          BRICKLINK_COOKIE: ${{ secrets.BRICKLINK_COOKIE }}
        run: |
          set -euo pipefail
          export PYTHONPATH="$PWD"
          mkdir -p outputs/market
          python -m brickovery.cli refresh-cache --config configs/config.v1.yaml --output-dir outputs/market

      - name: Show last m2.error events (this run)
        if: always()
        run: |
          set -euo pipefail
          LOG_DIR="data base/logs/run-${RUN_ID}"
          echo "RUN_ID=${RUN_ID}"
          echo "UPSTREAM_COMMIT_SHA=${UPSTREAM_COMMIT_SHA:-}"
          echo "LOG_DIR=${LOG_DIR}"

          if [ ! -d "$LOG_DIR" ]; then
            echo "No log dir found for this run. Listing available logs:"
            find "data base/logs" -maxdepth 3 -type f -name "*.jsonl" -print || true
            exit 0
          fi

          mapfile -d '' files < <(find "$LOG_DIR" -type f -name "*.jsonl" -print0 | sort -z)
          if [ ${#files[@]} -eq 0 ]; then
            echo "No jsonl files found under: $LOG_DIR"
            find "$LOG_DIR" -type f -print || true
            exit 0
          fi

          echo "== m2.error (if any) =="
          for f in "${files[@]}"; do
            if grep -q '"event":"m2.error"' "$f"; then
              echo "--- $f ---"
              grep '"event":"m2.error"' "$f" | tail -n 50 || true
            fi
          done

      - name: Verify refresh_report exists and fail if errors>0
        if: always()
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, glob, sys
          paths = sorted(glob.glob("outputs/market/refresh_report.*.json"))
          if not paths:
              print("ERROR: No outputs/market/refresh_report.*.json found")
              sys.exit(1)
          rp = paths[-1]
          with open(rp, "r", encoding="utf-8") as f:
              report = json.load(f)
          errors = int(report.get("errors", 0))
          refreshed = int(report.get("refreshed_items", 0))
          skipped = int(report.get("skipped_items", 0))
          print(f"refresh_report: {rp}")
          print(f"errors={errors} refreshed_items={refreshed} skipped_items={skipped}")
          if errors > 0:
              sys.exit(f"ERROR: M2 refresh-cache reported errors={errors}")
          PY

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: brickovery-m2
          path: |
            outputs/market/**
            data base/logs/**
